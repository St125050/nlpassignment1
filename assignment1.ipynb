{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II2PRO5fhN3e",
        "outputId": "cdd6319d-3b57-4cbe-c8c9-f20eca2efea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import nltk\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkDXP5FYhXIY",
        "outputId": "14fc3fdd-2d74-4e67-9a83-85834ff1980a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.26.4', '2.5.1+cu121')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nr8WzkJzhaeW",
        "outputId": "3712c41d-0420-44c6-a73d-c7767f723a32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "# Create a corpus containing only documents from the 'earn' category\n",
        "corpus = brown.sents()\n",
        "\n",
        "# Limit the corpus to the first 1000 sentences for demonstration purposes\n",
        "corpus = [[word.lower() for word in sentence] for sentence in corpus]\n",
        "corpus = corpus[:1000]"
      ],
      "metadata": {
        "id": "r4Ub242CheRb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))"
      ],
      "metadata": {
        "id": "WY-foun3hng1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njRm8cMrhtA4",
        "outputId": "72c0f983-7c30-4f1c-9944-c92fb2f6f6a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4272"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ],
      "metadata": {
        "id": "x9qT0KD-hvwa",
        "outputId": "c15f374e-f530-474b-843f-6b564a457355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')\n",
        "word2index['<UNK>'] = 0\n",
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()}"
      ],
      "metadata": {
        "id": "dsZ2WHvU0gNU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# index the corpus\n",
        "X_i = Counter(flatten(corpus))\n",
        "skip_grams = []\n",
        "# Prepare the skipgram\n",
        "\n",
        "for doc in corpus:\n",
        "    # The skipgram has a window size of 2\n",
        "    for i in range(2, len(doc)-2):\n",
        "        center = doc[i]\n",
        "        outside = [doc[i-1], doc[i+1],doc[i+2],doc[i-2]]\n",
        "        for each_out in outside:\n",
        "            skip_grams.append((center, each_out))\n",
        "X_ik_skipgrams = Counter(skip_grams)\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "\n",
        "    #check whether the co-occurences between w_i and w_j is available\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "        #if not exist, then set to 1 \"laplace smoothing\"\n",
        "    except:\n",
        "        x_ij = 1\n",
        "\n",
        "    #set xmax\n",
        "    x_max = 100\n",
        "    #set alpha\n",
        "    alpha = 0.75\n",
        "\n",
        "    #if co-ocurrence does not exceeed xmax, then just multiply with some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij / x_max)**alpha\n",
        "    #otherwise, set to 1\n",
        "    else:\n",
        "        result = 1\n",
        "\n",
        "    return result\n",
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {}  # for keeping the co-occurrences\n",
        "weighting_dic = {}  # scaling the percentage of sampling\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgrams.get(bigram) is not None:  # matches\n",
        "        co_occer = X_ik_skipgrams[bigram]  # get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1  # + 1 for stability issue\n",
        "        X_ik[(bigram[1], bigram[0])] = co_occer + 1  # count also for the opposite\n",
        "        # print(X_ik[(bigram[1], bigram[0])])  # count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)"
      ],
      "metadata": {
        "id": "rHm39VAA0mqj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create pairs of center word, and outside word\n",
        "\n",
        "def random_batch(batch_size, corpus, window_size=2):\n",
        "    skipgrams = []\n",
        "    for doc in corpus:\n",
        "        for i in range(window_size, len(doc)-window_size):\n",
        "            center = word2index[doc[i]]\n",
        "            outside = [word2index[doc[i-j]] for j in range(-window_size, window_size+1) if j != 0]\n",
        "            for each_out in outside:\n",
        "                skipgrams.append([center, each_out])\n",
        "\n",
        "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
        "    inputs, labels = [], []\n",
        "    for index in random_index:\n",
        "        inputs.append([skipgrams[index][0]])\n",
        "        labels.append([skipgrams[index][1]])\n",
        "\n",
        "    return np.array(inputs), np.array(labels)\n",
        "\n",
        "\n",
        "x, y = random_batch(2, corpus)\n",
        "import math\n",
        "\n",
        "def random_batch_glove(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "\n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "\n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "\n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "\n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)\n",
        "x.shape  #batch_size, 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDPYazbw1sCa",
        "outputId": "117d8908-c2c7-4132-a3f8-ee2a635a6486"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4E-u9OT1xz_",
        "outputId": "e826c8f5-4789-4e37-e22a-6ddb45e9e975"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2366],\n",
              "       [1424]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOCxhWIb1zQs",
        "outputId": "a614b4d2-0b4a-4f03-c102-128f4978945b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY8ezAN910wW",
        "outputId": "8603f426-93a7-4956-c2f8-b13780fc6ef2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4273"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(63314, 2)\n",
        "x_tensor = torch.LongTensor(x)\n",
        "embedding(x_tensor).shape  #(batch_size, 1, emb_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A64X5aT15-O",
        "outputId": "e12e9ff5-eb77-4c0a-d22e-bc77c1f6b860"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Skipgram(nn.Module):\n",
        "\n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
        "\n",
        "    def forward(self, center, outside, all_vocabs):\n",
        "        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n",
        "        outside_embedding    = self.embedding_center(outside) #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embedding = self.embedding_center(all_vocabs) #(batch_size, voc_size, emb_size)\n",
        "\n",
        "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
        "        #batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n",
        "\n",
        "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
        "        #batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "\n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n",
        "\n",
        "        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "dpDPPgrP19JJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_center = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_outside = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "\n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_center(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_outside(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_outside(negative_words) # [batch_size, num_neg, emb_size]\n",
        "\n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "\n",
        "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
        "\n",
        "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
        "\n",
        "        return -torch.mean(loss)\n",
        "\n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "\n",
        "        return embeds"
      ],
      "metadata": {
        "id": "rYqEQi921_sK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Glove(nn.Module):\n",
        "\n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Glove, self).__init__()\n",
        "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
        "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
        "\n",
        "        self.center_bias       = nn.Embedding(voc_size, 1)\n",
        "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
        "\n",
        "    def forward(self, center, outside, coocs, weighting):\n",
        "        center_embeds  = self.embedding_center(center) #(batch_size, 1, emb_size)\n",
        "        outside_embeds = self.embedding_outside(outside) #(batch_size, 1, emb_size)\n",
        "\n",
        "        center_bias    = self.center_bias(center).squeeze(1)\n",
        "        target_bias    = self.outside_bias(outside).squeeze(1)\n",
        "\n",
        "        inner_product  = outside_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1)\n",
        "\n",
        "        loss = weighting * torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
        "\n",
        "        return torch.sum(loss)"
      ],
      "metadata": {
        "id": "pBGs79U02EjJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# setting the dataset\n",
        "glove_file = datapath('/content/glove.6B.100d.txt')\n",
        "model_gensim = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "UhYoDIGs2IQA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare all vocab of batch - 2 , vocab - 2 and embed - 2\n",
        "\n",
        "batch_size = 2\n",
        "voc_size   = len(vocab)\n",
        "emb_size = 2\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, voc_size)\n",
        "all_vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kFHfNdb8WIJ",
        "outputId": "8507d4c9-7f53-4824-f45c-f317a1d8598e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    1,    2,  ..., 4270, 4271,    0],\n",
              "        [   0,    1,    2,  ..., 4270, 4271,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_skipgram_positive = Skipgram(voc_size, emb_size)\n",
        "model_skipgram_positive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDToiJRt8ZOh",
        "outputId": "61de6e3f-aae9-4d35-c374-9e19e385a33f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Skipgram(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove = Glove(voc_size, emb_size)\n",
        "model_glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnfNXcoH8cIe",
        "outputId": "a92e565e-6b3c-4d07-e437-bd59f0f909d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Glove(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              "  (center_bias): Embedding(4273, 1)\n",
              "  (outside_bias): Embedding(4273, 1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_skipgram_negative = Skipgram(voc_size, emb_size)\n",
        "model_skipgram_negative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H92vloiB8cfE",
        "outputId": "ea8d6495-5056-448a-ae28-a2556cf4f308"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Skipgram(\n",
              "  (embedding_center): Embedding(4273, 2)\n",
              "  (embedding_outside): Embedding(4273, 2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.LongTensor(x)\n",
        "label_tensor = torch.LongTensor(y)\n",
        "loss_skipgram_positive = model_skipgram_positive(input_tensor, label_tensor, all_vocabs)\n",
        "loss_skipgram_negative = model_skipgram_negative(input_tensor, label_tensor, all_vocabs)\n",
        "# x, y, cooc, weighting = random_batch_glove(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "# loss_glove = model_glove(torch.LongTensor(x), torch.LongTensor(y), torch.LongTensor(cooc), torch.LongTensor(weighting))\n",
        "batch_size = 2\n",
        "emb_size   = 2\n",
        "model_skipgram_positive      = Skipgram(voc_size, emb_size)\n",
        "optimizer_skipgram_positive  = optim.Adam(model_skipgram_positive.parameters(), lr=0.001)\n",
        "optimizer_skipgram_negative  = optim.Adam(model_skipgram_negative.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_glove = optim.Adam(model_glove.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "amx3EvJC8etG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "num_epochs = 10\n",
        "total_start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_tensor = torch.LongTensor(input_batch)\n",
        "    label_tensor = torch.LongTensor(label_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_skipgram_positive = model_skipgram_positive(input_tensor, label_tensor, all_vocabs)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_skipgram_positive.zero_grad()\n",
        "    loss_skipgram_positive.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_skipgram_positive.step()\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Positive Skigram\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_skipgram_positive:2.6f}| time: {epoch_mins}m {epoch_secs}s\")\n",
        "# Record the ending time\n",
        "total_end = time.time()\n",
        "\n",
        "# Calculate and print the total runtime\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWpaluT48hb1",
        "outputId": "d4b8cf7b-45f2-43a2-812a-663918e5fdb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Skigram\n",
            "Epoch      1 | Loss: 9.612683| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      2 | Loss: 9.719759| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      3 | Loss: 9.866372| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      4 | Loss: 8.562344| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      5 | Loss: 9.555107| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      6 | Loss: 8.814235| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      7 | Loss: 8.913357| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      8 | Loss: 10.221360| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch      9 | Loss: 8.728003| time: 0m 0s\n",
            "Positive Skigram\n",
            "Epoch     10 | Loss: 9.641560| time: 0m 0s\n",
            "Total runtime: 1.88 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "\n",
        "total_start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_tensor = torch.LongTensor(input_batch)\n",
        "    label_tensor = torch.LongTensor(label_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_skipgram_negative = model_skipgram_negative(input_tensor, label_tensor, all_vocabs)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_skipgram_negative.zero_grad()\n",
        "    loss_skipgram_negative.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_skipgram_negative.step()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Negative Skigram\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_skipgram_negative:2.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "# Record the ending time\n",
        "total_end = time.time()\n",
        "\n",
        "# Calculate and print the total runtime\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks9ueFWU8lNB",
        "outputId": "8f7bf171-b20e-4bde-cc59-09f3cfe135c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Skigram\n",
            "Epoch      1 | Loss: 9.184487 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      2 | Loss: 11.816785 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      3 | Loss: 8.389261 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      4 | Loss: 11.150173 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      5 | Loss: 8.586180 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      6 | Loss: 9.139943 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      7 | Loss: 8.526684 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      8 | Loss: 8.895833 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch      9 | Loss: 8.522974 | time: 0m 0s\n",
            "Negative Skigram\n",
            "Epoch     10 | Loss: 9.015740 | time: 0m 0s\n",
            "Total runtime: 1.96 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    #get batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch_glove(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch)\n",
        "\n",
        "    #predict\n",
        "    loss_glove = model_glove(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "\n",
        "    #backprogate\n",
        "    optimizer_glove.zero_grad()\n",
        "    loss_glove.backward()\n",
        "\n",
        "    #update alpha\n",
        "    optimizer_glove.step()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    #print the loss_skipgram_positive\n",
        "    # if (epoch + 1) % 1000 == 0:\n",
        "    print(\"Glove\")\n",
        "    print(f\"Epoch {epoch+1:6.0f} | Loss: {loss_glove:2.6f} | time: {epoch_mins}m {epoch_secs}s\")\n",
        "total_runtime = total_end - total_start\n",
        "print(f\"Total runtime: {total_runtime:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Uo9WEwq8r2A",
        "outputId": "3684815c-16c1-49c6-81fc-8339da3c5e79"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove\n",
            "Epoch      1 | Loss: 0.686887 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      2 | Loss: 0.018294 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      3 | Loss: 0.033439 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      4 | Loss: 7.187566 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      5 | Loss: 12.880122 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      6 | Loss: 0.704878 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      7 | Loss: 0.133139 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      8 | Loss: 0.178575 | time: 0m 0s\n",
            "Glove\n",
            "Epoch      9 | Loss: 0.383690 | time: 0m 0s\n",
            "Glove\n",
            "Epoch     10 | Loss: 0.492787 | time: 0m 0s\n",
            "Total runtime: 1.96 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(model, word):\n",
        "    try:\n",
        "        # Find the index\n",
        "        index = word2index[word]\n",
        "    except:\n",
        "        # if not found give the index of unknown token\n",
        "        index = word2index['<UNK>']\n",
        "\n",
        "    # get the word in terms of tensor\n",
        "    word = torch.LongTensor([word2index[word]])\n",
        "     # embed the center and the outside word and then find the final embed\n",
        "    embed_c = model.embedding_center(word)\n",
        "    embed_o = model.embedding_outside(word)\n",
        "    embed   = (embed_c + embed_o) / 2\n",
        "\n",
        "\n",
        "    return embed[0][0].item(), embed[0][1].item()\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def get_embed_for_corpus(model, words):\n",
        "    embeddings = {}\n",
        "\n",
        "    for word in words:\n",
        "        try:\n",
        "            index = word2index[word]\n",
        "        except KeyError:\n",
        "            index = word2index['<UNK>']\n",
        "\n",
        "        word_tensor = torch.LongTensor([index])\n",
        "\n",
        "        embed_c = model.embedding_center(word_tensor)\n",
        "        embed_o = model.embedding_outside(word_tensor)\n",
        "        embed = (embed_c + embed_o) / 2\n",
        "\n",
        "        # return as dictionary with key as the word and value as the array of its embedding\n",
        "        embeddings[word] = np.array([embed[0][0].item(), embed[0][1].item()])\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "wK3GgdKr8wY_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#more formally is to divide by its norm\n",
        "def cosine_similarity(A, B):\n",
        "    dot_product = np.dot(A, B)\n",
        "    norm_a = np.linalg.norm(A)\n",
        "    norm_b = np.linalg.norm(B)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "def cosine_similarity_for_corpus(embeddings, target_word):\n",
        "    # List to store (word, cosine_similarity) pairs\n",
        "    similarities = []\n",
        "\n",
        "    # Get the index of the target word or use the index for '<UNK>' if not found\n",
        "    target_index = word2index.get(target_word, word2index['<UNK>'])\n",
        "\n",
        "    # Get the vector for the target word\n",
        "    target_vector = embeddings[target_index]\n",
        "\n",
        "    # Iterate through all words in the embeddings dictionary\n",
        "    for word, vector in embeddings.items():\n",
        "        # Calculate the cosine similarity between the target word and the current word\n",
        "        similarity = cosine_similarity(target_vector, vector)\n",
        "\n",
        "        # Append the (word, cosine_similarity) pair to the list\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    return similarities"
      ],
      "metadata": {
        "id": "vCRo1SkG84En"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your .txt file\n",
        "file_path = '/content/word-test.v1.txt'\n",
        "\n",
        "# Read the content of the file\n",
        "with open(file_path, 'r') as file:\n",
        "    # Skip the first line\n",
        "    file.readline()\n",
        "\n",
        "    # Read the remaining content of the file\n",
        "    file_content = file.readlines()\n",
        "\n",
        "# Initialize variables to store relevant lines\n",
        "total_corpus = []\n",
        "\n",
        "# Variable to keep track of the current heading\n",
        "current_heading = None\n",
        "\n",
        "# Iterate through each line in the file content\n",
        "for line in file_content:\n",
        "    # Check if the line is a heading\n",
        "    if line.startswith(':'):\n",
        "        current_heading = line.strip()\n",
        "    else:\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        total_corpus.append(words)"
      ],
      "metadata": {
        "id": "XebkXpkc87L3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/word-test.v1.txt'\n",
        "\n",
        "# Read the content of the file\n",
        "with open(file_path, 'r') as file:\n",
        "    file_content = file.readlines()\n",
        "\n",
        "# Initialize variables to store relevant lines\n",
        "capital_common_countries = []\n",
        "past_tense = []\n",
        "\n",
        "# Variable to keep track of the current heading\n",
        "current_heading = None\n",
        "\n",
        "# Iterate through each line in the file content\n",
        "for line in file_content:\n",
        "    # Check if the line is a heading\n",
        "    if line.startswith(':'):\n",
        "        current_heading = line.strip()\n",
        "    elif current_heading == ': capital-common-countries':\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        capital_common_countries.append(words)\n",
        "    elif current_heading == ': gram7-past-tense':\n",
        "        # Split the line into individual words and convert to lowercase\n",
        "        words = [word.lower() for word in line.strip().split()]\n",
        "        past_tense.append(words)"
      ],
      "metadata": {
        "id": "nrDHmzeB9UVk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_of_country = [word for pair in capital_common_countries for word in pair]\n",
        "\n",
        "# Wrap the flattened list in another list\n",
        "resulting_capital_list = [flattened_list_of_country]\n",
        "\n",
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_of_past_tense = [word for pair in past_tense for word in pair]\n",
        "\n",
        "# Wrap the flattened list in another list\n",
        "resulting_capital_list = [flattened_list_of_country]\n",
        "resulting_past_tense_list = [flattened_list_of_past_tense]\n",
        "\n",
        "# Flatten the 2D list into a list of lists\n",
        "flattened_list_total_words = [word for pair in total_corpus for word in pair]\n",
        "# Wrap the flattened list in another list\n",
        "resulting_total_corpus = [flattened_list_total_words]\n",
        "\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "capital_list = list(set(flatten(resulting_capital_list)))\n",
        "past_tense_list = list(set(flatten(resulting_past_tense_list)))\n",
        "whole_corpus = list(set(flatten(resulting_total_corpus)))"
      ],
      "metadata": {
        "id": "dfNFVQjR9a1F"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the embeddings\n",
        "embed_capital_glove = get_embed_for_corpus(model_glove, capital_list)\n",
        "embed_capital_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, capital_list)\n",
        "embed_capital_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, capital_list)\n",
        "\n",
        "embed_past_tense_glove = get_embed_for_corpus(model_glove, past_tense_list)\n",
        "embed_past_tense_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, past_tense_list)\n",
        "embed_past_tense_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, past_tense_list)\n",
        "\n",
        "embed_total_glove = get_embed_for_corpus(model_glove, whole_corpus)\n",
        "embed_whole_skipgram_positive = get_embed_for_corpus(model_skipgram_positive, whole_corpus)\n",
        "embed_whole_skipgram_negative = get_embed_for_corpus(model_skipgram_negative, whole_corpus)\n",
        "# y_pred for glove for the capital list\n",
        "y_pred_glove_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_glove[i[1]] - embed_capital_glove[i[0]] + embed_capital_glove[i[2]]\n",
        "    y_pred_glove_country.append(y)\n",
        "# y_pred for glove for the past tense list\n",
        "y_pred_glove_past = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_glove[i[1]] - embed_past_tense_glove[i[0]] + embed_past_tense_glove[i[2]]\n",
        "    y_pred_glove_past.append(y)\n",
        "# y_pred for skipgram negative sampling for the capital list\n",
        "y_pred_neg_samp_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_skipgram_negative[i[1]] - embed_capital_skipgram_negative[i[0]] + embed_capital_skipgram_negative[i[2]]\n",
        "    y_pred_neg_samp_country.append(y)"
      ],
      "metadata": {
        "id": "OP6mTAAR9dxv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred for skipgram negative sampling for the past tense list\n",
        "y_pred_neg_samp_past = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_skipgram_negative[i[0]] - embed_past_tense_skipgram_negative[i[0]] + embed_past_tense_skipgram_negative[i[2]]\n",
        "    y_pred_neg_samp_past.append(y)\n",
        "# y_pred for skipgram positive sampling for the country list\n",
        "y_pred_positive_samp_country = []\n",
        "\n",
        "for i in capital_common_countries:\n",
        "    y = embed_capital_skipgram_positive[i[1]] - embed_capital_skipgram_positive[i[0]] + embed_capital_skipgram_positive[i[2]]\n",
        "    y_pred_positive_samp_country.append(y)\n",
        "# y_pred for skipgram positive sampling for the past tense list\n",
        "y_pred_positive_past_tense = []\n",
        "\n",
        "for i in past_tense:\n",
        "    y = embed_past_tense_skipgram_positive[i[1]] - embed_past_tense_skipgram_positive[i[0]] + embed_past_tense_skipgram_positive[i[2]]\n",
        "    y_pred_positive_past_tense.append(y)\n",
        "# find the cosine similarity\n",
        "#more formally is to divide by its norm\n",
        "def cosine_similarity(A, B):\n",
        "    dot_product = np.dot(A, B)\n",
        "    norm_a = np.linalg.norm(A)\n",
        "    norm_b = np.linalg.norm(B)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "def find_max_cosine_words(y_pred, embeddings):\n",
        "    \"\"\"\n",
        "    Find the word with the maximum cosine similarity for each vector in y_pred.\n",
        "\n",
        "    Parameters:\n",
        "    - y_pred: List of vectors for which to find the max cosine similarity words.\n",
        "    - embeddings: Dictionary of word embeddings.\n",
        "\n",
        "    Returns:\n",
        "    - List of words with the maximum cosine similarity for each vector in y_pred.\n",
        "    \"\"\"\n",
        "    max_cosine_words = []\n",
        "\n",
        "    for j in range(len(y_pred)):\n",
        "        max_cosine = -1\n",
        "        max_cosine_word = \"\"\n",
        "\n",
        "        for i in embeddings.keys():\n",
        "            cosine_temp = cosine_similarity(y_pred[j], embeddings[i])\n",
        "\n",
        "            if cosine_temp > max_cosine:\n",
        "                max_cosine_word = i\n",
        "                max_cosine = cosine_temp\n",
        "\n",
        "        max_cosine_words.append(max_cosine_word)\n",
        "\n",
        "    return max_cosine_words\n",
        "\n",
        "#Usage\n",
        "cosine_neg_samp_syntatical = find_max_cosine_words(y_pred_neg_samp_country, embed_capital_skipgram_negative)\n",
        "cosine_positive_samp_syntatical = find_max_cosine_words(y_pred_positive_samp_country, embed_capital_skipgram_positive)\n",
        "cosine_glove_syntatical = find_max_cosine_words(y_pred_glove_country, embed_capital_glove)\n",
        "from heapq import nlargest\n",
        "\n",
        "def find_next_10_cosine_words_for_word(target_word, embeddings, top_n=10):\n",
        "    \"\"\"\n",
        "    Find the next 10 words with the maximum cosine similarity for a user-provided specific word.\n",
        "\n",
        "    Parameters:\n",
        "    - target_word: The word for which to find the next 10 cosine similarity words.\n",
        "    - embeddings: Dictionary of word embeddings.\n",
        "    - top_n: Number of top words to retrieve for the target word (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    - List of the next 10 words with the maximum cosine similarity for the target word or [\"Word not in Corpus\"].\n",
        "    \"\"\"\n",
        "    if target_word not in embeddings:\n",
        "        return [\"Word not in Corpus\"]\n",
        "\n",
        "    target_vector = embeddings[target_word]\n",
        "    cosine_similarities = [(word, cosine_similarity(target_vector, embeddings[word])) for word in embeddings.keys()]\n",
        "    top_n_words = nlargest(top_n + 1, cosine_similarities, key=lambda x: x[1])\n",
        "\n",
        "    # Exclude the target word itself\n",
        "    top_n_words = [word for word, _ in top_n_words if word != target_word]\n",
        "\n",
        "    return top_n_words[:10]\n",
        "\n",
        "# Usage:\n",
        "user_target_word = 'greece'\n",
        "next_10_cosine_for_user_word = find_next_10_cosine_words_for_word(user_target_word, embed_whole_skipgram_negative, top_n=10)\n",
        "\n",
        "# Print the results\n",
        "if next_10_cosine_for_user_word == [\"Word not in Corpus\"]:\n",
        "    print(\"Word not in Corpus\")\n",
        "else:\n",
        "    print(f\"Next 10 similar words for user-provided word '{user_target_word}': {next_10_cosine_for_user_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvs83WEo9ija",
        "outputId": "acc93777-aae3-496e-8e9f-ccf469e2c244"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next 10 similar words for user-provided word 'greece': ['wrote', 'apparently', 'acceptable', 'known', 'rapid', 'dollar', 'speak', 'mostly', 'stronger', 'writing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions, true_words):\n",
        "    \"\"\"\n",
        "    Calculate accuracy based on predictions and true words.\n",
        "\n",
        "    Parameters:\n",
        "    - predictions: List of predicted words.\n",
        "    - true_words: List of true words.\n",
        "\n",
        "    Returns:\n",
        "    - Accuracy as a percentage.\n",
        "    \"\"\"\n",
        "    total_trials = len(predictions)\n",
        "    total_correct = sum(1 for pred_word in predictions if pred_word in true_words)\n",
        "\n",
        "    accuracy = (total_correct / total_trials) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Usage:\n",
        "semantic_accuracy_neg_samp = calculate_accuracy(find_max_cosine_words(y_pred_neg_samp_country, embed_whole_skipgram_negative), [true_word[3] for true_word in capital_common_countries])\n",
        "semantic_accuracy_pos_samp = calculate_accuracy(find_max_cosine_words(y_pred_positive_samp_country, embed_whole_skipgram_positive), [true_word[3] for true_word in capital_common_countries])\n",
        "semantic_accuracy_glove = calculate_accuracy(find_max_cosine_words(y_pred_glove_country, embed_total_glove), [true_word[3] for true_word in capital_common_countries])\n",
        "print(\"Semantic Accuracy of Skipgram Negative: {:.10f}%\".format(semantic_accuracy_neg_samp))\n",
        "print(\"Semantic Accuracy of Skipgram Positive: {:.10f}%\".format(semantic_accuracy_pos_samp))\n",
        "print(\"Semantic Accuracy of Glove: {:.10f}%\".format(semantic_accuracy_glove))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfGq8S_19qJW",
        "outputId": "7d778ed0-9d15-42d9-8231-7bebd93bff41"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Accuracy of Skipgram Negative: 14.4268774704%\n",
            "Semantic Accuracy of Skipgram Positive: 14.2292490119%\n",
            "Semantic Accuracy of Glove: 14.4268774704%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/word-test.v1.txt'\n",
        "output_file_path = '/content/word-test-without-first-line.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Write all lines except the first line to the output file\n",
        "    output_file.writelines(lines[1:])\n",
        "\n",
        "print(f\"First line removed and content saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkoTQFBj9v8A",
        "outputId": "6caa62ab-d05b-440b-ce24-76833accedc5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First line removed and content saved to: /content/word-test-without-first-line.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/word-test.v1.txt'\n",
        "output_file_path = '/content/capital.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Flag to indicate whether to start writing lines\n",
        "    start_writing = False\n",
        "\n",
        "    # Iterate through lines\n",
        "    for line in lines:\n",
        "        # Check if the line starts with ': gram7-past-tense'\n",
        "        if line.startswith(': capital-common-countries'):\n",
        "            # Set the flag to start writing\n",
        "            start_writing = True\n",
        "        elif line.startswith(':'):\n",
        "            # If a new section header is encountered, stop writing\n",
        "            start_writing = False\n",
        "\n",
        "        # Write lines to the output file if the flag is True\n",
        "        if start_writing:\n",
        "            output_file.write(line)\n",
        "\n",
        "print(f\"Lines starting with ': capital-countries' saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZfzGH5Q-BYS",
        "outputId": "2ddb3acc-b440-4249-af05-29d48b88e17e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines starting with ': capital-countries' saved to: /content/capital.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_score_sem = model_gensim.evaluate_word_analogies(datapath('/content/capital.txt'))\n",
        "print(\"Semtatical Accuracy of Model Gensim:\", analogy_score_sem[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyxMVjyX-ONR",
        "outputId": "5e702f21-b326-49d7-8c59-a3f5c2f1550a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semtatical Accuracy of Model Gensim: 0.9387351778656127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions, true_words):\n",
        "    \"\"\"\n",
        "    Calculate accuracy based on predictions and true words.\n",
        "\n",
        "    Parameters:\n",
        "    - predictions: List of predicted words.\n",
        "    - true_words: List of true words.\n",
        "\n",
        "    Returns:\n",
        "    - Accuracy as a percentage.\n",
        "    \"\"\"\n",
        "    total_trials = len(predictions)\n",
        "    total_correct = sum(1 for pred_word in predictions if pred_word in true_words)\n",
        "\n",
        "    accuracy = (total_correct / total_trials) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Usage:\n",
        "syntatical_accuracy_neg_samp = calculate_accuracy(find_max_cosine_words(y_pred_neg_samp_past, embed_whole_skipgram_negative), [true_word[3] for true_word in past_tense])\n",
        "syntatical_accuracy_pos_samp = calculate_accuracy(find_max_cosine_words(y_pred_positive_past_tense, embed_whole_skipgram_positive), [true_word[3] for true_word in past_tense])\n",
        "syntatical_accuracy_glove = calculate_accuracy(find_max_cosine_words(y_pred_glove_past, embed_total_glove), [true_word[3] for true_word in past_tense])\n",
        "print(\"Syntatical Accuracy of Skipgram Negative: {:.2f}%\".format(syntatical_accuracy_neg_samp))\n",
        "print(\"Syntatical Accuracy of Skipgram Positive: {:.2f}%\".format(syntatical_accuracy_pos_samp))\n",
        "print(\"Syntatical Accuracy of Glove: {:.2f}%\".format(syntatical_accuracy_glove))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0vuH0gY-VAA",
        "outputId": "afb1395f-0b14-4c78-a934-64f62590673e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syntatical Accuracy of Skipgram Negative: 0.00%\n",
            "Syntatical Accuracy of Skipgram Positive: 11.09%\n",
            "Syntatical Accuracy of Glove: 12.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/word-test.v1.txt'\n",
        "output_file_path = '/content/past_tense_lines.txt'\n",
        "\n",
        "# Open the input file for reading\n",
        "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
        "    # Read all lines from the input file\n",
        "    lines = input_file.readlines()\n",
        "\n",
        "# Open the output file for writing\n",
        "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "    # Flag to indicate whether to start writing lines\n",
        "    start_writing = False\n",
        "\n",
        "    # Iterate through lines\n",
        "    for line in lines:\n",
        "        # Check if the line starts with ': gram7-past-tense'\n",
        "        if line.startswith(': gram7-past-tense'):\n",
        "            # Set the flag to start writing\n",
        "            start_writing = True\n",
        "        elif line.startswith(':'):\n",
        "            # If a new section header is encountered, stop writing\n",
        "            start_writing = False\n",
        "\n",
        "        # Write lines to the output file if the flag is True\n",
        "        if start_writing:\n",
        "            output_file.write(line)\n",
        "\n",
        "print(f\"Lines starting with ': gram7-past-tense' saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UqG_Y3Q-aCh",
        "outputId": "e2a2fffa-9979-45f4-ccb0-c3b7b184081c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines starting with ': gram7-past-tense' saved to: /content/past_tense_lines.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_score_syn = model_gensim.evaluate_word_analogies(datapath('/content/past_tense_lines.txt'))\n",
        "print(\"Syntatical Accuracy of Model Gensim:\", analogy_score_syn[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOy04aVt-kFM",
        "outputId": "90660917-6430-4edb-e5f7-651fb8cd2b6c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syntatical Accuracy of Model Gensim: 0.5544871794871795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'wordsim_similarity_goldstandard.txt'\n",
        "\n",
        "# Define the column names\n",
        "columns = ['word_1', 'word_2', 'similarity_index']\n",
        "\n",
        "# Read the text file into a pandas DataFrame with specified column names\n",
        "df = pd.read_csv(file_path, sep='\\t', header=None, names=columns)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BbycP2P5-nj_",
        "outputId": "ac514393-d8da-434d-c2d1-6d39018c8e24"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word_1    word_2  similarity_index\n",
              "0         tiger       cat              7.35\n",
              "1         tiger     tiger             10.00\n",
              "2         plane       car              5.77\n",
              "3         train       car              6.31\n",
              "4    television     radio              6.77\n",
              "..          ...       ...               ...\n",
              "198     rooster    voyage              0.62\n",
              "199        noon    string              0.54\n",
              "200       chord     smile              0.54\n",
              "201   professor  cucumber              0.31\n",
              "202        king   cabbage              0.23\n",
              "\n",
              "[203 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-784016fd-53bc-4e16-af0d-c004c338f65f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>rooster</td>\n",
              "      <td>voyage</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>noon</td>\n",
              "      <td>string</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>chord</td>\n",
              "      <td>smile</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>professor</td>\n",
              "      <td>cucumber</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>king</td>\n",
              "      <td>cabbage</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>203 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-784016fd-53bc-4e16-af0d-c004c338f65f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-784016fd-53bc-4e16-af0d-c004c338f65f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-784016fd-53bc-4e16-af0d-c004c338f65f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36330649-5c5e-4adf-9d7e-03c74a94b31d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36330649-5c5e-4adf-9d7e-03c74a94b31d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36330649-5c5e-4adf-9d7e-03c74a94b31d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09c1172a-a53e-4eff-b00f-c2238fcf2c6e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09c1172a-a53e-4eff-b00f-c2238fcf2c6e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 203,\n  \"fields\": [\n    {\n      \"column\": \"word_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 130,\n        \"samples\": [\n          \"marathon\",\n          \"century\",\n          \"vodka\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 177,\n        \"samples\": [\n          \"Jackson\",\n          \"fauna\",\n          \"interview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5039610876799423,\n        \"min\": 0.23,\n        \"max\": 10.0,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          8.34,\n          6.63,\n          3.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_embed(model_skipgram_negative,'<UNK>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWfJhoeP-tmb",
        "outputId": "3c419b2b-d357-4224-d74b-c53900e145f8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.09843230247497559, -0.24945229291915894)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    word_1 = row['word_1']\n",
        "    word_2 = row['word_2']\n",
        "\n",
        "    try:\n",
        "        # Attempt to get embeddings and compute the dot product\n",
        "        embed_1_neg_samp = get_embed(model_skipgram_negative, word_1)\n",
        "        embed_2_neg_samp = get_embed(model_skipgram_negative, word_2)\n",
        "        embed_1_pos_samp = get_embed(model_skipgram_positive, word_1)\n",
        "        embed_2_pos_samp = get_embed(model_skipgram_positive, word_2)\n",
        "        embed_1_glove = get_embed(model_glove, word_1)\n",
        "        embed_2_glove = get_embed(model_glove, word_2)\n",
        "\n",
        "    except KeyError:\n",
        "        # Handle the case where one or both words are not present in the model\n",
        "        # Replace missing embeddings with the embedding of '<UNK>' or any other suitable value\n",
        "        embed_1_neg_samp = get_embed(model_skipgram_negative, '<UNK>')\n",
        "        embed_2_neg_samp = get_embed(model_skipgram_negative, '<UNK>')\n",
        "        embed_1_pos_samp = get_embed(model_skipgram_positive, '<UNK>')\n",
        "        embed_2_pos_samp = get_embed(model_skipgram_positive, '<UNK>')\n",
        "        embed_1_glove = get_embed(model_glove, '<UNK>')\n",
        "        embed_2_glove = get_embed(model_glove, '<UNK>')\n",
        "\n",
        "    # Compute the dot product and update the DataFrame\n",
        "    df.at[index, 'dot_product_neg_samp'] = np.dot(embed_1_neg_samp, embed_2_neg_samp)\n",
        "    df.at[index, 'dot_product_pos_samp'] = np.dot(embed_1_pos_samp, embed_2_pos_samp)\n",
        "    df.at[index, 'dot_product_glove'] = np.dot(embed_1_glove, embed_2_glove)\n",
        "\n",
        "df[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TIme2mPDAa8h",
        "outputId": "2fb9f185-6f02-4151-fdc2-dbe7b6022b37"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word_1  word_2  similarity_index  dot_product_neg_samp  \\\n",
              "0       tiger     cat              7.35              0.071915   \n",
              "1       tiger   tiger             10.00              0.071915   \n",
              "2       plane     car              5.77              0.071915   \n",
              "3       train     car              6.31              0.071915   \n",
              "4  television   radio              6.77             -0.202235   \n",
              "5       media   radio              7.42              0.071915   \n",
              "6       bread  butter              6.19              0.071915   \n",
              "7    cucumber  potato              5.92              0.071915   \n",
              "8      doctor   nurse              7.00              1.625690   \n",
              "9   professor  doctor              6.62              0.315840   \n",
              "\n",
              "   dot_product_pos_samp  dot_product_glove  \n",
              "0              1.079078           0.484521  \n",
              "1              1.079078           0.484521  \n",
              "2              1.079078           0.484521  \n",
              "3              1.079078           0.484521  \n",
              "4             -0.477442           0.194055  \n",
              "5              1.079078           0.484521  \n",
              "6              1.079078           0.484521  \n",
              "7              1.079078           0.484521  \n",
              "8             -0.314029          -0.818755  \n",
              "9              0.391521          -0.314967  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-581961a7-ef6e-4c76-aae0-440d895b77e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_1</th>\n",
              "      <th>word_2</th>\n",
              "      <th>similarity_index</th>\n",
              "      <th>dot_product_neg_samp</th>\n",
              "      <th>dot_product_pos_samp</th>\n",
              "      <th>dot_product_glove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train</td>\n",
              "      <td>car</td>\n",
              "      <td>6.31</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>television</td>\n",
              "      <td>radio</td>\n",
              "      <td>6.77</td>\n",
              "      <td>-0.202235</td>\n",
              "      <td>-0.477442</td>\n",
              "      <td>0.194055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>media</td>\n",
              "      <td>radio</td>\n",
              "      <td>7.42</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bread</td>\n",
              "      <td>butter</td>\n",
              "      <td>6.19</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cucumber</td>\n",
              "      <td>potato</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>1.079078</td>\n",
              "      <td>0.484521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doctor</td>\n",
              "      <td>nurse</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.625690</td>\n",
              "      <td>-0.314029</td>\n",
              "      <td>-0.818755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>professor</td>\n",
              "      <td>doctor</td>\n",
              "      <td>6.62</td>\n",
              "      <td>0.315840</td>\n",
              "      <td>0.391521</td>\n",
              "      <td>-0.314967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-581961a7-ef6e-4c76-aae0-440d895b77e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-581961a7-ef6e-4c76-aae0-440d895b77e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-581961a7-ef6e-4c76-aae0-440d895b77e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a388a78b-d0e8-4aa8-adc5-dbaa3643cae3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a388a78b-d0e8-4aa8-adc5-dbaa3643cae3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a388a78b-d0e8-4aa8-adc5-dbaa3643cae3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"word_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"doctor\",\n          \"plane\",\n          \"bread\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"tiger\",\n          \"potato\",\n          \"cat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2140588490221094,\n        \"min\": 5.77,\n        \"max\": 10.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7.0,\n          10.0,\n          7.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_neg_samp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5073628327353333,\n        \"min\": -0.20223483535796394,\n        \"max\": 1.6256901481322679,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.20223483535796394,\n          0.3158398953256434,\n          0.07191536461315096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_pos_samp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6247954350148102,\n        \"min\": -0.4774416948269504,\n        \"max\": 1.0790777180136866,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.4774416948269504,\n          0.39152111352423447,\n          1.0790777180136866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dot_product_glove\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.453299705568987,\n        \"min\": -0.8187547266001083,\n        \"max\": 0.48452148233549863,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.19405452741913365,\n          -0.31496665794786516,\n          0.48452148233549863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Compute the Spearman correlation between the provided similarity scores and your models' dot products\n",
        "correlation_neg, _ = spearmanr(df['similarity_index'], df['dot_product_neg_samp'])\n",
        "correlation_pos, _ = spearmanr(df['similarity_index'], df['dot_product_pos_samp'])\n",
        "correlation_glove, _ = spearmanr(df['similarity_index'], df['dot_product_glove'])\n",
        "\n",
        "\n",
        "# Display the correlation coefficient\n",
        "print(f\"Spearman Correlation Coefficient of Skipgram Negative: {correlation_neg:.4f}\")\n",
        "print(f\"Spearman Correlation Coefficient of Skipgram Positive: {correlation_pos:.4f}\")\n",
        "print(f\"Spearman Correlation Coefficient of Glove: {correlation_glove:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7KEvI3-Ad1_",
        "outputId": "1fca6d3b-9b7a-48b8-b5c3-cb413cfbcd72"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Correlation Coefficient of Skipgram Negative: -0.0024\n",
            "Spearman Correlation Coefficient of Skipgram Positive: 0.0389\n",
            "Spearman Correlation Coefficient of Glove: 0.0640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding y_true based on the mean of similarity index in the df\n",
        "y_true = df['similarity_index'].mean()\n",
        "\n",
        "print(f\"y_true: {y_true:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giT0uAhpAggk",
        "outputId": "a65efef9-7306-4081-c13d-e384286712c8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true: 5.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the correlation coeffiecient of the gensim model using the predefined function\n",
        "correlation_coefficient = model_gensim.evaluate_word_pairs(datapath('/content/wordsim_similarity_goldstandard.txt'))\n",
        "print(f\"Correlation coefficient: {correlation_coefficient[1][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oST9Ui4tAif4",
        "outputId": "50138b99-3071-4969-b437-5af9c03f4ee2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_whole_glove = get_embed_for_corpus(model_glove, vocab)\n",
        "embed_whole_neg_skg = get_embed_for_corpus(model_skipgram_negative, vocab)\n",
        "embed_whole_pos_skg = get_embed_for_corpus(model_skipgram_positive, vocab)"
      ],
      "metadata": {
        "id": "cpo3VBfMAnM2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming you have a Gensim Word2Vec model named 'model'\n",
        "# You can replace 'Word2Vec' with the specific Gensim model you are using\n",
        "\n",
        "# Save the Gensim model to a file using pickle\n",
        "gensim_model_path = 'model_gensim.pkl'\n",
        "\n",
        "with open(gensim_model_path, 'wb') as model_file:\n",
        "    pickle.dump(model_gensim, model_file)\n",
        "\n",
        "print(f\"Gensim model saved to: {gensim_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvUrfCi7AwMA",
        "outputId": "de9c5970-3332-48e2-97cd-d594322b5052"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim model saved to: model_gensim.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your pickled Gensim model file\n",
        "gensim_model_path = 'model_gensim.pkl'\n",
        "\n",
        "# Load the Gensim model from the pickle file\n",
        "with open(gensim_model_path, 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "for i in range (1,10):\n",
        "    print(loaded_model.most_similar('language')[i][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY9IvU97Azm1",
        "outputId": "7b755670-539d-4d08-8bae-b19c7be010a1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word\n",
            "spoken\n",
            "arabic\n",
            "english\n",
            "dialect\n",
            "vocabulary\n",
            "text\n",
            "translation\n",
            "words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_pos_skg\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_skipgram_positive.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L-7KOz6A5tx",
        "outputId": "9c6d3a86-68e4-42f1-ee89-acc36b852eb2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_skipgram_positive.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_neg_skg\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_skipgram_negative.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANIvnaLNBFSH",
        "outputId": "66d898b4-7d75-450c-8edc-2b9837a0ef79"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_skipgram_negative.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_capital_skipgram_negative is your embedding dictionary\n",
        "embedding_dict = embed_whole_glove\n",
        "\n",
        "# Specify the file path to save the pickle file\n",
        "pickle_file_path = 'embed_glove.pkl'\n",
        "\n",
        "# Open the file in binary write mode and dump the dictionary\n",
        "with open(pickle_file_path, 'wb') as pickle_file:\n",
        "    pickle.dump(embedding_dict, pickle_file)\n",
        "\n",
        "print(f\"Embedding dictionary saved to: {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1dfvOiaBIsQ",
        "outputId": "efe1d2c4-f114-4ac5-dcc9-d870aa785d63"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dictionary saved to: embed_glove.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_skipgram_positive.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_neg = pickle.load(pickle_file)\n",
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_skipgram_negative.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_pos = pickle.load(pickle_file)\n",
        "import pickle\n",
        "\n",
        "# Specify the path to the pickled file on the server\n",
        "pickle_file_path = 'embed_glove.pkl'\n",
        "\n",
        "# Load the embedding dictionary from the pickled file\n",
        "with open(pickle_file_path, 'rb') as pickle_file:\n",
        "    embedding_dict_glove = pickle.load(pickle_file)\n",
        "user_target_word = \"run\"\n",
        "next_10_cosine_for_user_word = find_next_10_cosine_words_for_word(user_target_word, embedding_dict_glove, top_n=10)\n",
        "\n",
        "# Print the results\n",
        "if next_10_cosine_for_user_word == [\"Word not in Corpus\"]:\n",
        "    print(\"Word not in Corpus\")\n",
        "else:\n",
        "    print(f\"Next 10 similar words for user-provided word '{user_target_word}': {next_10_cosine_for_user_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4JpMokFBNN9",
        "outputId": "b9e1c7be-0b20-4361-ad0c-fa69ce3f43c8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next 10 similar words for user-provided word 'run': ['causes', 'essential', 'letters', 'want', 'resent', 'december', 'cotten', 'hopes', 'standpoint', 'representation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "id": "s9jT570BBXPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d26a8d-abdc-4669-ae9b-9d5a4b120ce3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.41.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the pickled model\n",
        "def load_model(model_path):\n",
        "    with open(model_path, 'rb') as file:\n",
        "        model = pickle.load(file)\n",
        "    return model\n",
        "\n",
        "# Example function to get embedding for a word using a loaded model (GloVe or similar)\n",
        "def get_embed(model, word):\n",
        "    # Assuming model is a word-to-embedding dictionary (for GloVe, for example)\n",
        "    return model.get(word, np.zeros(300))  # Return a zero vector if word not found (300 is common dimension)\n",
        "\n",
        "# Function to compute the dot product and retrieve top 10 most similar contexts\n",
        "def compute_dot_product(query, model, corpus_embeddings):\n",
        "    # Get the embedding for the query word\n",
        "    query_embedding = get_embed(model, query)\n",
        "\n",
        "    # Compute dot products for all embeddings in the corpus\n",
        "    similarities = []\n",
        "    for word, embedding in corpus_embeddings.items():\n",
        "        similarity = np.dot(query_embedding, embedding)\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    # Sort similarities and return the top 10 most similar contexts\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:10]\n",
        "\n",
        "# Streamlit app to handle the user input and display results\n",
        "def main():\n",
        "    # Load the model (update the path to your actual model)\n",
        "    model_path = '/content/embed_glove.pkl'  # Update the path to your pickled model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # For simplicity, assume we have a corpus of words already embedded\n",
        "    corpus_embeddings = {word: get_embed(model, word) for word in model.keys()}  # Example corpus\n",
        "\n",
        "    # Title of the app\n",
        "    st.title(\"Search Similar Contexts\")\n",
        "\n",
        "    # Input box for query\n",
        "    query = st.text_input(\"Enter a word or query:\", \"\")\n",
        "\n",
        "    # Display a message if no query is entered\n",
        "    if query:\n",
        "        top_10_similar = compute_dot_product(query, model, corpus_embeddings)\n",
        "\n",
        "        # Display results\n",
        "        st.write(f\"Top 10 Similar Contexts for: **{query}**\")\n",
        "\n",
        "        # Show results as a table\n",
        "        result_data = [{\"Word\": word, \"Similarity\": similarity} for word, similarity in top_10_similar]\n",
        "        st.table(result_data)\n",
        "    else:\n",
        "        st.write(\"Please enter a query to search for similar contexts.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "O5AkAvRC672i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e6d237-a72d-4301-be3e-3c935d11c9b3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-17 13:46:19.703 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.029 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-01-17 13:46:20.034 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.042 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.046 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.058 Session state does not function when running a script without `streamlit run`\n",
            "2025-01-17 13:46:20.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-17 13:46:20.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Lzx1eYz5671T"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drBiHEBh67vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-OxZ9co67V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "St1inDxe67SY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}